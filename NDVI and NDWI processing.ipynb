{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T01:49:27.155671Z",
     "start_time": "2018-07-17T01:49:27.107379Z"
    }
   },
   "outputs": [],
   "source": [
    "from datacube import Datacube\n",
    "cdc = Datacube(config='/g/data/u46/users/ext547/ewater/cambodia_cube/cambodia.conf')\n",
    "from datacube_stats.statistics import GeoMedian\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/g/data/u46/users/sc0554/datacube-hyptest/')\n",
    "import \n",
    "\n",
    "#Import external dea-notebooks functions using relative link to Scripts directory\n",
    "import sys\n",
    "sys.path.append('/g/data/u46/users/sc0554/dea-notebooks/Scripts')\n",
    "import DEAPlotting\n",
    "import BandIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:44:39.705549Z",
     "start_time": "2018-07-17T03:44:39.683796Z"
    }
   },
   "outputs": [],
   "source": [
    "def LoadAreaOfInterest(study_area):\n",
    "    '''\n",
    "    Firstly, LoadAreaOfInterest checks whether a pickle, that contains an xarray of nbar data, \n",
    "    is saved in the output folder. If there is no pickle, the function searches the \n",
    "    \"AreaOfInterest\" function to gain lat/lon information for that particular study_area. If \n",
    "    there is no lat/lon coordinates in the AreaOfInterest function, then an error is returned. \n",
    "    If the coordinates are found, nbar data is loaded and masked. Finally data from all \n",
    "    sensors are concatenated together into one xarray.\n",
    "   \n",
    "    Last modified: March 2018\n",
    "    \n",
    "    Author: Erin Telfer\n",
    "    \n",
    "    Inputs: \n",
    "    study_area - the name of the study area\n",
    "    '''\n",
    "    \n",
    "    study_area=study_area.lower().replace(\" \",\"\")\n",
    "    pickle_location=('{0}{1}.pkl'.format(output_folder,study_area))\n",
    "    try:\n",
    "        nbar_clean= pickle.load( open(pickle_location, \"rb\" ) )\n",
    "        print(\"Nbar pickle has been found on file\")\n",
    "        print(\"Nbar pickle has been loaded\")\n",
    "        return(nbar_clean)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            print(\"No {0}.pkl file found on file\".format(study_area))\n",
    "            print(\"Location information from the AreaOfInterest function has been read\")\n",
    "\n",
    "            lat_min, lat_max, lon_min, lon_max = AreaOfInterest(study_area)\n",
    "            \n",
    "            print(\"Loading Cambodia Cube data\")\n",
    "            sensor_clean = {}\n",
    "\n",
    "            #define wavelengths/bands of interest\n",
    "            bands_of_interest = ['green',\n",
    "                                 'red', \n",
    "                                 'nir',\n",
    "                                 'pixel_qa',\n",
    "                                 #'blue',\n",
    "                                 #'swir2',\n",
    "                                 #'swir1'\n",
    "                                 ]\n",
    "\n",
    "            #query is created\n",
    "            query = {'time': (start_of_epoch, end_of_epoch),}\n",
    "            query['x'] = (lon_min, lon_max)\n",
    "            query['y'] = (lat_max, lat_min)\n",
    "            query['crs'] = 'EPSG:4326'\n",
    "\n",
    "            for sensor in sensors: #loop through specified\n",
    "                sensor_nbar = cdc.load(product= sensor+'_usgs_sr_scene',\n",
    "                                       measurements = bands_of_interest,group_by='solar_day', \n",
    "                                       **query) #load nbar\n",
    "                #retrieve the projection information before masking/sorting\n",
    "                crs = sensor_nbar.crs\n",
    "                crswkt = sensor_nbar.crs.wkt\n",
    "                affine = sensor_nbar.affine\n",
    "                #assign pq data variable\n",
    "                sensor_pq= sensor_nbar.pixel_qa\n",
    "                #create and use quality and cloud masks\n",
    "                mask_components = {'cloud_shadow': 'no_cloud_shadow',\n",
    "                           'cloud': 'no_cloud',}\n",
    "                quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "                good_data = quality_mask.loc[start_of_epoch:end_of_epoch]\n",
    "                sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "                del (sensor_nbar)\n",
    "\n",
    "                #calculate the percentage cloud free for each scene\n",
    "                cloud_free = masking.make_mask(sensor_pq,\n",
    "                                               cloud_shadow= 'no_cloud_shadow',cloud= 'no_cloud')\n",
    "                mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_free_threshold\n",
    "                \n",
    "                del(cloud_free)\n",
    "                #discard data that does not meet the cloud_free_threshold\n",
    "                mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', \n",
    "                                                                           how='all')\n",
    "                nodata_mask=mostly_good.mean(dim=('x','y')) >= -9998\n",
    "                mostly_good=mostly_good.drop('pixel_qa')\n",
    "                mostly_good=mostly_good.where(nodata_mask).dropna(dim='time',\n",
    "                                                               how='all') \n",
    "                del(sensor_nbar2)\n",
    "                #assign masked data to array\n",
    "                sensor_clean[sensor] = mostly_good\n",
    "\n",
    "                print('loaded %s' % sensor) \n",
    "            print('ls load complete')\n",
    "\n",
    "\n",
    "            #data from different sensors are joined together and sorted so that observations are sorted by time rather than sensor\n",
    "            nbar_clean = xr.concat(sensor_clean.values(), 'time')\n",
    "            nbar_clean = nbar_clean.sortby('time')\n",
    "            nbar_clean.attrs['crs'] = crs\n",
    "            nbar_clean.attrs['affin|e'] = affine          \n",
    "                    \n",
    "            print(\"saving nbar data as {0}.pkl\".format(study_area))\n",
    "\n",
    "            pickle.dump(nbar_clean, open(pickle_location,\"wb\")) #save nbar as pickle\n",
    "            return nbar_clean\n",
    "        except TypeError:\n",
    "            print(\"please add lat/lon details to AreaOfInterest function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:44:40.301215Z",
     "start_time": "2018-07-17T03:44:40.289444Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define function to define the coordinates for the study area#Define \n",
    "def AreaOfInterest(study_area):\n",
    "    if study_area == 'phumsrahkaev':\n",
    "        lat_min = 13.000 #down\n",
    "        lat_max = 13.100 #up\n",
    "        lon_min = 103.300 #left\n",
    "        lon_max = 103.400 #right  \n",
    "    elif study_area == 'outapaong':\n",
    "        lat_min = 12.600 #down\n",
    "        lat_max = 12.800 #up\n",
    "        lon_min = 103.600 #left\n",
    "        lon_max = 103.800 #right\n",
    "    elif study_area == 'mondulkiri':\n",
    "        lat_min = 12.863 #down\n",
    "        lat_max = 13.663 #up\n",
    "        lon_min = 106.350 #left\n",
    "        lon_max = 107.236 #right\n",
    "    elif study_area == 'krongstungtreng':\n",
    "        lat_min = 13.181 #down\n",
    "        lat_max = 13.681 #up\n",
    "        lon_min = 105.781 #left\n",
    "        lon_max = 106.381 #right\n",
    "    elif study_area == 'kaohnheaek':\n",
    "        lat_min = 13.000 #down\n",
    "        lat_max = 13.100 #up\n",
    "        lon_min = 107.000 #left\n",
    "        lon_max = 107.100 #right\n",
    "    elif study_area == 'neakleoang':\n",
    "        lat_min = 11.246 #down\n",
    "        lat_max = 11.532 #up\n",
    "        lon_min = 105.141 #left\n",
    "        lon_max = 105.380 #right\n",
    "    elif study_area == 'tonlesaplake':\n",
    "        lat_min = 13.020 #down\n",
    "        lat_max = 13.120 #up\n",
    "        lon_min = 103.740 #left\n",
    "        lon_max = 103.840 #right\n",
    "    elif study_area == 'maximum_extent':\n",
    "        lat_min = 9.25 #down\n",
    "        lat_max = 15.25 #up\n",
    "        lon_min = 101.75 #left\n",
    "        lon_max = 108.25 #right     \n",
    "    else:\n",
    "        print('FileNotFoundError')\n",
    "    return (lat_min, lat_max, lon_min, lon_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:44:40.529535Z",
     "start_time": "2018-07-17T03:44:40.520425Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_band_image_subplots(ds, num_cols, figsize = [10,40], left  = 0.125, \n",
    "                              right = 0.9, bottom = 0.1, top = 0.9, \n",
    "                              wspace = 0.2, hspace = 0.4):\n",
    "    '''\n",
    "    one_band_image_subplots takes a dataset with one band and multiple time steps, \n",
    "    and plots them in image. \n",
    "    Last modified: March 2018\n",
    "    Author: Mike Barnes\n",
    "    Modified by: Claire Krause and Erin Telfer\n",
    "    \n",
    "    Inputs: \n",
    "    ds -   Dataset containing the bands to be plotted\n",
    "    num_cols - number of columns for the subplot\n",
    "    \n",
    "    Optional:\n",
    "    figsize - dimensions for the output figure\n",
    "    left  - the space on the left side of the subplots of the figure\n",
    "    right - the space on the right side of the subplots of the figure\n",
    "    bottom - the space on the bottom of the subplots of the figure\n",
    "    top - the space on the top of the subplots of the figure\n",
    "    wspace - the amount of width reserved for blank space between subplots\n",
    "    hspace - the amount of height reserved for white space between subplots\n",
    "    '''\n",
    "    # Find the number of rows/columns we need, based on the number of time steps in ds\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    timesteps = ds.time.size\n",
    "    num_rows = int(np.ceil(timesteps/num_cols))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize = figsize)\n",
    "    fig.subplots_adjust(left  = left, right = right, bottom = bottom, top = top, \n",
    "                        wspace = wspace, hspace = hspace)\n",
    "    try: #loop through all scenes, prepare imagery and create subplots\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            image_ds = ds.isel(time =i)\n",
    "            ax.set_title(str(image_ds.time.values)[0:10])\n",
    "            ax.imshow(image_ds, interpolation = 'nearest') #plot image as subplot\n",
    "    except IndexError: #if there are an odd number of plots, this code will allow plotting of images\n",
    "        fig.delaxes(ax)\n",
    "        plt.draw() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:44:40.688847Z",
     "start_time": "2018-07-17T03:44:40.683318Z"
    }
   },
   "outputs": [],
   "source": [
    "#define study area\n",
    "study_area = 'phumsrahkaev' #name of study area\n",
    "study_area=study_area.lower().replace(\" \",\"\") #reformat to remove uppercase and spaces\n",
    "\n",
    "#define temporal range ()\n",
    "start_of_epoch = '2003-01-01'\n",
    "end_of_epoch =  '2017-12-01'\n",
    "\n",
    "#define Landsat sensors of interest\n",
    "sensors = ['ls5', 'ls8']\n",
    "\n",
    "cloud_free_threshold = 0.10 \n",
    "\n",
    "#specify output folder\n",
    "output_folder= '/g/data/u46/users/sc0554/NDVI_NDWI_hyptest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:48:07.801945Z",
     "start_time": "2018-07-17T03:44:40.869744Z"
    }
   },
   "outputs": [],
   "source": [
    "nbar_clean=LoadAreaOfInterest(study_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:48:08.307699Z",
     "start_time": "2018-07-17T03:48:07.806117Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NDVI = BandIndices.calculate_indices(nbar_clean, 'NDVI')\n",
    "NDWI = BandIndices.calculate_indices(nbar_clean, 'NDWI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T03:49:15.326119Z",
     "start_time": "2018-07-17T03:48:08.310743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(100, 2, sharex='col', sharey='row', figsize = (12, 500))\n",
    "for i in range(100):\n",
    "    NDVIplot = axes[i][0].imshow(NDVI.isel(time=i).values)\n",
    "    axes[i][1].imshow(NDWI.isel(time=i).values)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
