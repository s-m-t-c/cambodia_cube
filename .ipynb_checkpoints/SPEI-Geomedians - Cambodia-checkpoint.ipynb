{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T03:16:39.112923Z",
     "start_time": "2018-09-28T03:16:39.081109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datacube import Datacube\n",
    "cdc = Datacube(config='/g/data/u46/users/ext547/ewater/cambodia_cube/cambodia.conf', app = \"Polygon drill\")\n",
    "from datacube_stats.statistics import GeoMedian\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "from datacube.utils import geometry\n",
    "\n",
    "import fiona\n",
    "import rasterio.features\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "import calendar\n",
    "\n",
    "#Import external dea-notebooks functions using relative link to Scripts directory\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append('/g/data/u46/users/sc0554/dea-notebooks/10_Scripts/')\n",
    "import DEAPlotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T23:26:21.303156Z",
     "start_time": "2018-08-12T23:26:21.266224Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def LoadAreaOfInterest(study_area):\n",
    "    '''\n",
    "    Firstly, LoadAreaOfInterest checks whether a pickle, that contains an xarray of nbar data, \n",
    "    is saved in the output folder. If there is no pickle, the function searches the \n",
    "    \"AreaOfInterest\" function to gain lat/lon information for that particular study_area. If \n",
    "    there is no lat/lon coordinates in the AreaOfInterest function, then an error is returned. \n",
    "    If the coordinates are found, nbar data is loaded and masked. Finally data from all \n",
    "    sensors are concatenated together into one xarray.\n",
    "   \n",
    "    Last modified: March 2018\n",
    "    \n",
    "    Author: Erin Telfer\n",
    "    \n",
    "    Inputs: \n",
    "    study_area - the name of the study area\n",
    "    '''\n",
    "    \n",
    "    study_area=study_area.lower().replace(\" \",\"\")\n",
    "    pickle_location=('{0}{1}.pkl'.format(output_folder,study_area))\n",
    "    try:\n",
    "        nbar_clean= pickle.load( open(pickle_location, \"rb\" ) )\n",
    "        print(\"Nbar pickle has been found on file\")\n",
    "        print(\"Nbar pickle has been loaded\")\n",
    "        return(nbar_clean)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            print(\"No {0}.pkl file found on file\".format(study_area))\n",
    "            print(\"Location information from the AreaOfInterest function has been read\")\n",
    "\n",
    "            lat_min, lat_max, lon_min, lon_max = AreaOfInterest(study_area)\n",
    "            \n",
    "            print(\"Loading Cambodia Cube data\")\n",
    "            sensor_clean = {}\n",
    "\n",
    "            #define wavelengths/bands of interest\n",
    "            bands_of_interest = ['green',\n",
    "                                 'swir1', \n",
    "                                 'nir',\n",
    "                                 'pixel_qa',\n",
    "                                 #'blue',\n",
    "                                 #'swir2',\n",
    "                                 #'swir1'\n",
    "                                 ]\n",
    "\n",
    "            #query is created\n",
    "            query = {'time': (start_of_epoch, end_of_epoch),}\n",
    "            query['x'] = (lon_min, lon_max)\n",
    "            query['y'] = (lat_max, lat_min)\n",
    "            query['crs'] = 'EPSG:4326'\n",
    "\n",
    "            for sensor in sensors: #loop through specified\n",
    "                sensor_nbar = cdc.load(product= sensor+'_usgs_sr_scene',\n",
    "                                       measurements = bands_of_interest,group_by='solar_day',\n",
    "                                       **query) #load nbar , dask_chunks = {'x':200, 'y':200}\n",
    "                #retrieve the projection information before masking/sorting\n",
    "                crs = sensor_nbar.crs\n",
    "                crswkt = sensor_nbar.crs.wkt\n",
    "                affine = sensor_nbar.affine\n",
    "                #assign pq data variable\n",
    "                sensor_pq= sensor_nbar.pixel_qa\n",
    "                #create and use quality and cloud masks\n",
    "                mask_components = {'cloud_shadow': 'no_cloud_shadow',\n",
    "                           'cloud': 'no_cloud',}\n",
    "                quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "                good_data = quality_mask.loc[start_of_epoch:end_of_epoch]\n",
    "                sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "                del (sensor_nbar)\n",
    "\n",
    "                #calculate the percentage cloud free for each scene\n",
    "                cloud_free = masking.make_mask(sensor_pq,\n",
    "                                               cloud_shadow= 'no_cloud_shadow',cloud= 'no_cloud')\n",
    "                mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_free_threshold\n",
    "                \n",
    "                del(cloud_free)\n",
    "                #discard data that does not meet the cloud_free_threshold\n",
    "                mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', \n",
    "                                                                           how='all')\n",
    "                nodata_mask=mostly_good.mean(dim=('x','y')) >= -9998\n",
    "                mostly_good=mostly_good.drop('pixel_qa')\n",
    "                mostly_good=mostly_good.where(nodata_mask).dropna(dim='time',\n",
    "                                                               how='all') \n",
    "                del(sensor_nbar2)\n",
    "                #assign masked data to array\n",
    "                sensor_clean[sensor] = mostly_good\n",
    "\n",
    "                print('loaded %s' % sensor) \n",
    "            print('ls load complete')\n",
    "\n",
    "\n",
    "            #data from different sensors are joined together and sorted so that observations are sorted by time rather than sensor\n",
    "            nbar_clean = xr.concat(sensor_clean.values(), 'time')\n",
    "            nbar_clean = nbar_clean.sortby('time')\n",
    "            nbar_clean.attrs['crs'] = crs\n",
    "            nbar_clean.attrs['affin|e'] = affine          \n",
    "                    \n",
    "            print(\"saving nbar data as {0}.pkl\".format(study_area))\n",
    "\n",
    "            pickle.dump(nbar_clean, open(pickle_location,\"wb\")) #save nbar as pickle\n",
    "            return nbar_clean\n",
    "        except TypeError:\n",
    "            print(\"please add lat/lon details to AreaOfInterest function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T03:16:39.146168Z",
     "start_time": "2018-09-28T03:16:39.134687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Define function to define the coordinates for the study area#Define \n",
    "def AreaOfInterest(study_area):\n",
    "    if study_area == 'phumsrahkaev':\n",
    "        lat_min = 13.000 #down\n",
    "        lat_max = 13.100 #up\n",
    "        lon_min = 103.300 #left\n",
    "        lon_max = 103.400 #right  \n",
    "    elif study_area == 'outapaong':\n",
    "        lat_min = 12.600 #down\n",
    "        lat_max = 12.800 #up\n",
    "        lon_min = 103.600 #left\n",
    "        lon_max = 103.800 #right\n",
    "    elif study_area == 'mondulkiri':\n",
    "        lat_min = 12.863 #down\n",
    "        lat_max = 13.663 #up\n",
    "        lon_min = 106.350 #left\n",
    "        lon_max = 107.236 #right\n",
    "    elif study_area == 'krongstungtreng':\n",
    "        lat_min = 13.181 #down\n",
    "        lat_max = 13.681 #up\n",
    "        lon_min = 105.781 #left\n",
    "        lon_max = 106.381 #right\n",
    "    elif study_area == 'kaohnheaek':\n",
    "        lat_min = 13.000 #down\n",
    "        lat_max = 13.100 #up\n",
    "        lon_min = 107.000 #left\n",
    "        lon_max = 107.100 #right\n",
    "    elif study_area == 'neakleoang':\n",
    "        lat_min = 11.246 #down\n",
    "        lat_max = 11.532 #up\n",
    "        lon_min = 105.141 #left\n",
    "        lon_max = 105.380 #right\n",
    "    elif study_area == 'tonlesaplake':\n",
    "        lat_min = 13.020 #down\n",
    "        lat_max = 13.120 #up\n",
    "        lon_min = 103.740 #left\n",
    "        lon_max = 103.840 #right\n",
    "    elif study_area == 'maximum_extent':\n",
    "        lat_min = 9.25 #down\n",
    "        lat_max = 15.25 #up\n",
    "        lon_min = 101.75 #left\n",
    "        lon_max = 108.25 #right\n",
    "    elif study_area == 'kampongchhnang':\n",
    "        lat_min = 12 #down\n",
    "        lat_max = 12.25 #up\n",
    "        lon_min = 104.75 #left\n",
    "        lon_max = 105.0 #right        \n",
    "    else:\n",
    "        print('FileNotFoundError')\n",
    "    return (lat_min, lat_max, lon_min, lon_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T03:16:39.158051Z",
     "start_time": "2018-09-28T03:16:39.148951Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_your_netcdf(data, dataset_name, filename, crs):\n",
    "\n",
    "    \"\"\"\n",
    "    This function turns an xarray dataarray into a dataset so we can write it to netcdf. \n",
    "    It adds on a crs definition from the original array. data = your xarray dataset, dataset_name \n",
    "    is a string describing your variable\n",
    "    \n",
    "    Last modified: May 2018\n",
    "    Author: Bex Dunn    \n",
    "    \"\"\" \n",
    "   \n",
    "    #turn array into dataset so we can write the netcdf\n",
    "    if isinstance(data,xr.DataArray):\n",
    "        dataset= data.to_dataset(name=dataset_name)\n",
    "    elif isinstance(data,xr.Dataset):\n",
    "        dataset = data\n",
    "    else:\n",
    "        print('your data might be the wrong type, it is: '+type(data))\n",
    "    #grab our crs attributes to write a spatially-referenced netcdf\n",
    "    dataset.attrs['crs'] = crs\n",
    "\n",
    "    try:\n",
    "        write_dataset_to_netcdf(dataset, filename)\n",
    "    except RuntimeError as err:\n",
    "        print(\"RuntimeError: {0}\".format(err))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T03:16:39.176038Z",
     "start_time": "2018-09-28T03:16:39.161134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Define function to create subplots of all scenes within an array as subplots\n",
    "def one_band_image_subplots(ds, num_cols, figsize = [10,40], left  = 0.125, \n",
    "                              right = 0.9, bottom = 0.1, top = 0.9, \n",
    "                              wspace = 0.2, hspace = 0.4):\n",
    "    '''\n",
    "    one_band_image_subplots takes a dataset with one band and multiple time steps, \n",
    "    and plots them in image. \n",
    "    Last modified: March 2018\n",
    "    Author: Mike Barnes\n",
    "    Modified by: Claire Krause and Erin Telfer\n",
    "    \n",
    "    Inputs: \n",
    "    ds -   Dataset containing the bands to be plotted\n",
    "    num_cols - number of columns for the subplot\n",
    "    \n",
    "    Optional:\n",
    "    figsize - dimensions for the output figure\n",
    "    left  - the space on the left side of the subplots of the figure\n",
    "    right - the space on the right side of the subplots of the figure\n",
    "    bottom - the space on the bottom of the subplots of the figure\n",
    "    top - the space on the top of the subplots of the figure\n",
    "    wspace - the amount of width reserved for blank space between subplots\n",
    "    hspace - the amount of height reserved for white space between subplots\n",
    "    '''\n",
    "    # Find the number of rows/columns we need, based on the number of time steps in ds\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    timesteps = ds.time.size\n",
    "    num_rows = int(np.ceil(timesteps/num_cols))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize = figsize)\n",
    "    fig.subplots_adjust(left  = left, right = right, bottom = bottom, top = top, \n",
    "                        wspace = wspace, hspace = hspace)\n",
    "    try: #loop through all scenes, prepare imagery and create subplots\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            image_ds = ds.rainfall.isel(time =i)\n",
    "            ax.set_title(str(image_ds.time.values)[0:10])\n",
    "            ax.imshow(image_ds, interpolation = 'nearest') #plot image as subplot\n",
    "    except IndexError: #if there are an odd number of plots, this code will allow plotting of images\n",
    "        fig.delaxes(ax)\n",
    "        plt.draw() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Query datacube for Landsat data and Calculate Geomedians "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Read in SPEI data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:19:59.486017Z",
     "start_time": "2018-09-27T05:19:59.040042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cambodia_spei = xr.open_dataset('/g/data/u46/users/sc0554/drought_indices_cambodia/climate_indices_output/cambodia_spei.nc')\n",
    "cambodia_masked_spei = xr.open_dataset('/g/data/u46/users/sc0554/drought_indices_cambodia/climate_indices_output/cambodia_masked_spei.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Calculate quantiles **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:20:00.307549Z",
     "start_time": "2018-09-27T05:20:00.296027Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cambodia_mean_spei_03 = cambodia_masked_spei.spei_gamma_03.mean(dim=('latitude', 'longitude'))\n",
    "cambodia_mean_spei_06 = cambodia_masked_spei.spei_gamma_06.mean(dim=('latitude', 'longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:20:30.783740Z",
     "start_time": "2018-09-27T05:20:30.772363Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.199103593826294, -0.48335041105747223, 0.03167547658085823, 0.495951808989048, 2.0509073734283447]\n"
     ]
    }
   ],
   "source": [
    "spei_quantiles = cambodia_mean_spei_03.quantile([0,0.25, 0.5, 0.75, 1], dim = ['time'], keep_attrs = True, )\n",
    "spei_quantiles = spei_quantiles.values.tolist()\n",
    "# spei_quantiles = [item for sublist in spei_quantiles for item in sublist]\n",
    "# spei_quantiles = [item for sublist in spei_quantiles for item in sublist]\n",
    "print(spei_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T05:21:40.090496Z",
     "start_time": "2018-09-27T05:21:40.060789Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quartiles\n",
    "\n",
    "spei_q1 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 < spei_quantiles[1]) &\n",
    "                                 (cambodia_mean_spei_03 >= spei_quantiles[0]), drop=True)\n",
    "spei_q2 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 < spei_quantiles[2]) &\n",
    "                                 (cambodia_mean_spei_03 >= spei_quantiles[1]), drop=True)\n",
    "spei_q3 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 < spei_quantiles[3]) &\n",
    "                                 (cambodia_mean_spei_03 >= spei_quantiles[2]), drop=True)\n",
    "spei_q4 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 <= spei_quantiles[4]) &\n",
    "                                 (cambodia_mean_spei_03 >= spei_quantiles[3]), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T07:08:20.273637Z",
     "start_time": "2018-09-17T07:08:20.237391Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hard boundaries\n",
    "\n",
    "# spei_q1 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 < -1) &\n",
    "#                                  (cambodia_mean_spei_03 >= -2.199104), drop=True)\n",
    "# spei_q2 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 < 0) &\n",
    "#                                  (cambodia_mean_spei_03 >= -1), drop=True)\n",
    "# spei_q3 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 < 1) &\n",
    "#                                  (cambodia_mean_spei_03 >= 0), drop=True)\n",
    "# spei_q4 = cambodia_mean_spei_03.where((cambodia_mean_spei_03 <= 2.050907) &\n",
    "#                                  (cambodia_mean_spei_03 >= 1), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T07:08:35.935007Z",
     "start_time": "2018-09-17T07:08:35.873676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spei_q1.time.to_netcdf(\"spei_q1_dates_hard.nc\")\n",
    "spei_q2.time.to_netcdf(\"spei_q2_dates_hard.nc\")\n",
    "spei_q3.time.to_netcdf(\"spei_q3_dates_hard.nc\")\n",
    "spei_q4.time.to_netcdf(\"spei_q4_dates_hard.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T04:36:21.028226Z",
     "start_time": "2018-08-13T04:36:21.023694Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#define Landsat sensors of interest\n",
    "sensors = ['ls5','ls8']\n",
    "\n",
    "cloud_free_threshold = 0.10 \n",
    "\n",
    "#specify output folder\n",
    "output_folder= '/g/data/u46/users/sc0554/spei_geomedians/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T03:48:14.704076Z",
     "start_time": "2018-08-13T03:35:49.697137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nbar_clean=LoadAreaOfInterest(study_area)\n",
    "# nbar_clean= pickle.load( open(\"/g/data/u46/users/sc0554/drought_indices_cambodia/spei_geomedians/kampongchhnang.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  Select Landsat data using SPEI Quartile dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Select every landsat observation within a list of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T04:36:37.728762Z",
     "start_time": "2018-08-13T04:36:37.725077Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "months = nbar_clean.time.astype('datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T04:36:56.098887Z",
     "start_time": "2018-08-13T04:36:45.765683Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spei_nbar_q1 = []\n",
    "spei_nbar_q2 = []\n",
    "spei_nbar_q3 = []\n",
    "spei_nbar_q4 = []\n",
    "\n",
    "for index, ds in nbar_clean.groupby(months):\n",
    "    if index in spei_q1_dates.time.values.astype('datetime64[M]'):\n",
    "        spei_nbar_q1.append(ds)\n",
    "    if index in spei_q2_dates.time.values.astype('datetime64[M]'):\n",
    "        spei_nbar_q2.append(ds)\n",
    "    if index in spei_q3_dates.time.values.astype('datetime64[M]'):\n",
    "        spei_nbar_q3.append(ds)\n",
    "    if index in spei_q4_dates.time.values.astype('datetime64[M]'):\n",
    "        spei_nbar_q4.append(ds)\n",
    "        \n",
    "spei_nbar_q1 = xr.concat(spei_nbar_q1, dim = 'time')\n",
    "spei_nbar_q2 = xr.concat(spei_nbar_q2, dim = 'time')\n",
    "spei_nbar_q3 = xr.concat(spei_nbar_q3, dim = 'time')\n",
    "spei_nbar_q4 = xr.concat(spei_nbar_q4, dim = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T06:23:49.265742Z",
     "start_time": "2018-08-10T06:23:48.895965Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#SPEI geomedians\n",
    "spei_q1_geomedian = GeoMedian().compute(spei_q1)\n",
    "spei_q2_geomedian = GeoMedian().compute(spei_q2)\n",
    "spei_q3_geomedian = GeoMedian().compute(spei_q3)\n",
    "spei_q4_geomedian = GeoMedian().compute(spei_q4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T23:43:45.608086Z",
     "start_time": "2018-08-12T23:27:18.052439Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datacube_stats.statistics import GeoMedian\n",
    "spei_nbar_q1_geomedian = GeoMedian().compute(spei_nbar_q1)\n",
    "spei_nbar_q2_geomedian = GeoMedian().compute(spei_nbar_q2)\n",
    "spei_nbar_q3_geomedian = GeoMedian().compute(spei_nbar_q3)\n",
    "spei_nbar_q4_geomedian = GeoMedian().compute(spei_nbar_q4)\n",
    "\n",
    "geomedians = [spei_nbar_q1_geomedian, spei_nbar_q2_geomedian, spei_nbar_q3_geomedian, spei_nbar_q4_geomedian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T02:03:31.368161Z",
     "start_time": "2018-08-13T02:03:30.957940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_your_netcdf(spei_nbar_q2_geomedian, 'spei_nbar_q2', '/g/data/u46/users/sc0554/drought_indices_cambodia/spei_geomedians/spei_nbar_q2', spei_nbar_q2_geomedian.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T23:43:57.793773Z",
     "start_time": "2018-08-12T23:43:55.468141Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#spei_nbar_q1_geomedian.to_netcdf(\"spei_nbar_q1_geomedian.nc\")\n",
    "# spei_nbar_q2_geomedian.to_netcdf(\"spei_nbar_q2_geomedian.nc\")\n",
    "# spei_nbar_q3_geomedian.to_netcdf(\"spei_nbar_q3_geomedian.nc\")\n",
    "# spei_nbar_q4_geomedian.to_netcdf(\"spei_nbar_q4_geomedian.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
